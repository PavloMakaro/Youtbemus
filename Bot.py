import logging
import requests
import time
import json
import base64
import re
from datetime import datetime, timedelta
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters, CallbackQueryHandler
from telegram.constants import ParseMode, ChatAction

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
TOKEN = "8377691734:AAGywySfCYU8lI9UWQUHW9CHdEKFXkl2fe8"
ADMIN_ID = None  # –ú–æ–∂–µ—Ç–µ –≤–ø–∏—Å–∞—Ç—å —Å–≤–æ–π ID –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- –ú–û–ó–ì –ë–û–¢–ê (API POLLINATIONS) ---
class PollinationsBrain:
    def __init__(self):
        self.base_text_url = "https://text.pollinations.ai/"
        self.models_list_url = "https://text.pollinations.ai/models"
        self.image_url_base = "https://pollinations.ai/p/"
        
        # –ö—ç—à –º–æ–¥–µ–ª–µ–π
        self.text_models = []
        self.last_models_update = 0
        self.default_text_model = "openai" # –§–æ–ª–±—ç–∫
        self.default_image_model = "flux"

        # –ü–µ—Ä–≤–∏—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
        self.refresh_models()

    def refresh_models(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ —Å API"""
        # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–µ —á–∞—â–µ —Ä–∞–∑–∞ –≤ —á–∞—Å, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å
        if time.time() - self.last_models_update < 3600 and self.text_models:
            return

        try:
            response = requests.get(self.models_list_url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π. –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å 'name'
                self.text_models = [m.get('name') for m in data if m.get('name')]
                self.last_models_update = time.time()
                logger.info(f"‚úÖ Models updated. Found {len(self.text_models)} models.")
                # –ï—Å–ª–∏ openai –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ, —Å—Ç–∞–≤–∏–º –ø–µ—Ä–≤—É—é –ø–æ–ø–∞–≤—à—É—é—Å—è –∫–∞–∫ –¥–µ—Ñ–æ–ª—Ç
                if self.default_text_model not in self.text_models and self.text_models:
                    self.default_text_model = self.text_models[0]
            else:
                logger.error(f"Failed to fetch models: Status {response.status_code}")
        except Exception as e:
            logger.error(f"Error fetching models: {e}")
            # –§–æ–ª–±—ç–∫ —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ —Å–∞–π—Ç –ª–µ–∂–∏—Ç
            if not self.text_models:
                self.text_models = ["openai", "gpt-4o", "claude-3-opus", "mistral-large", "gemini"]

    def generate_text(self, messages, model, seed=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        payload = {
            "messages": messages,
            "model": model,
            "jsonMode": False
        }
        if seed: payload["seed"] = seed

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º session –¥–ª—è keep-alive
            with requests.Session() as s:
                response = s.post(self.base_text_url, json=payload, timeout=60)
                if response.status_code == 200:
                    return response.text
                return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API ({response.status_code}): {response.text[:100]}"
        except Exception as e:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}"

    def generate_image_url(self, prompt, model="flux", seed=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É"""
        import urllib.parse
        clean_prompt = urllib.parse.quote(prompt)
        url = f"{self.image_url_base}{clean_prompt}?width=1024&height=1024&model={model}&nologo=true"
        if seed: url += f"&seed={seed}"
        return url

brain = PollinationsBrain()

# --- –õ–û–ì–ò–ö–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø –ö–û–ù–¢–ï–ö–°–¢–û–ú ---

SYSTEM_PROMPT = {
    "role": "system", 
    "content": (
        "–¢—ã ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π AI-–∞–≥–µ–Ω—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –±—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º. "
        "–¢—ã —É–º–µ–µ—à—å –ø–∏—Å–∞—Ç—å –∫–æ–¥, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –±–µ—Å–µ–¥—É. "
        "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å —á—Ç–æ-—Ç–æ, –æ—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–∏–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º, –±–æ—Ç —Å–∞–º —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ. "
        "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ—Å—è—Ç –¥–ª–∏–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è."
    )
}

async def check_context_expiry(context, chat_id):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –ø—Ä–æ—à–µ–ª –ª–∏ —á–∞—Å —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.
    –ï—Å–ª–∏ –ø—Ä–æ—à–µ–ª ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é.
    """
    last_time = context.user_data.get('last_interaction', 0)
    current_time = time.time()
    
    # 3600 —Å–µ–∫—É–Ω–¥ = 1 —á–∞—Å
    if current_time - last_time > 3600 and last_time != 0:
        context.user_data['history'] = [SYSTEM_PROMPT]
        context.user_data['last_interaction'] = current_time
        return True # –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–±—Ä–æ—à–µ–Ω
    
    context.user_data['last_interaction'] = current_time
    return False

async def reset_context(update, context):
    """–†—É—á–Ω–æ–π —Å–±—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    context.user_data['history'] = [SYSTEM_PROMPT]
    context.user_data['last_interaction'] = time.time()
    await update.message.reply_text("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞. –ú—ã –Ω–∞—á–∞–ª–∏ –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥!", parse_mode=ParseMode.MARKDOWN)

# --- –•–ï–ù–î–õ–ï–†–´ ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user.first_name
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    if 'text_model' not in context.user_data: 
        context.user_data['text_model'] = brain.default_text_model
    if 'image_model' not in context.user_data: 
        context.user_data['image_model'] = brain.default_image_model
    
    # –°–±—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    context.user_data['history'] = [SYSTEM_PROMPT]
    context.user_data['last_interaction'] = time.time()

    text = (
        f"–ü—Ä–∏–≤–µ—Ç, {user}! ü§ñ\n\n"
        "–Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –Ø –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞—é—Å—å –ø–æ–¥ —Ç–≤–æ–∏ –∑–∞–ø—Ä–æ—Å—ã.\n"
        "üïí **–§–∏—à–∫–∞:** –ï—Å–ª–∏ –º—ã –Ω–µ –æ–±—â–∞–µ–º—Å—è —á–∞—Å, —è –∑–∞–±—É–¥—É –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞.\n"
        "üîÑ **–°–±—Ä–æ—Å:** –ù–∞–ø–∏—à–∏ *'—Å–±—Ä–æ—Å'*, *'–Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥'* –∏–ª–∏ *'–∑–∞–±—É–¥—å'*, —á—Ç–æ–±—ã –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å –≤—Ä—É—á–Ω—É—é.\n\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/models - –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π\n"
        "/settings - –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å!"
    )
    await update.message.reply_text(text, parse_mode=ParseMode.MARKDOWN)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text
    chat_id = update.effective_chat.id
    
    # 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–±—Ä–æ—Å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    if await check_context_expiry(context, chat_id):
        await update.message.reply_text("‚è≥ –ü—Ä–æ—à–µ–ª —á–∞—Å, —è –Ω–∞—á–∞–ª –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥, —á—Ç–æ–±—ã –Ω–µ –ø—É—Ç–∞—Ç—å—Å—è.", quote=False)

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–º–∞–Ω–¥—É —Ä—É—á–Ω–æ–≥–æ —Å–±—Ä–æ—Å–∞
    reset_keywords = ['—Å–±—Ä–æ—Å', 'reset', '–∑–∞–±—É–¥—å', '–Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥', '–æ—á–∏—Å—Ç–∏', 'new chat', 'clear']
    if user_text.lower().strip() in reset_keywords:
        await reset_context(update, context)
        return

    # 2. –ò—â–µ–º —è–≤–Ω—É—é –ø—Ä–æ—Å—å–±—É —Å–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å
    # –ü—Ä–∏–º–µ—Ä: "–ò—Å–ø–æ–ª—å–∑—É–π –º–æ–¥–µ–ª—å gpt-4"
    text_lower = user_text.lower()
    brain.refresh_models() # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–≤–µ–∂–∏–π
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏
    found_model = None
    for m in brain.text_models:
        if m in text_lower and ("–∏—Å–ø–æ–ª—å–∑—É–π" in text_lower or "use" in text_lower or "–º–æ–¥–µ–ª—å" in text_lower):
            found_model = m
            break
            
    if found_model:
        context.user_data['text_model'] = found_model
        await update.message.reply_text(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ –º–æ–¥–µ–ª—å: **{found_model}**", parse_mode=ParseMode.MARKDOWN)
        # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º, –≤–¥—Ä—É–≥ —Ç–∞–º –±—ã–ª –µ—â–µ –∏ –≤–æ–ø—Ä–æ—Å

    # 3. –†–∏—Å–æ–≤–∞–Ω–∏–µ (Image Generation)
    draw_triggers = ["–Ω–∞—Ä–∏—Å—É–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π", "—Ñ–æ—Ç–æ", "–∫–∞—Ä—Ç–∏–Ω–∫–∞", "draw", "image of", "picture"]
    is_draw_request = any(user_text.lower().startswith(t) for t in draw_triggers)

    if is_draw_request:
        # –ß–∏—Å—Ç–∏–º –ø—Ä–æ–º–ø—Ç
        prompt = user_text
        for t in draw_triggers:
            prompt = re.sub(t, "", prompt, flags=re.IGNORECASE)
        prompt = prompt.strip()
        
        current_img_model = context.user_data.get('image_model', 'flux')
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_PHOTO)
        
        img_url = brain.generate_image_url(prompt, model=current_img_model, seed=update.message.message_id)
        
        try:
            await update.message.reply_photo(img_url, caption=f"üé® **{current_img_model}**", parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            await update.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–æ—Ç–æ: {e}")
        return

    # 4. –¢–µ–∫—Å—Ç–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ (—Å –ø–∞–º—è—Ç—å—é)
    current_model = context.user_data.get('text_model', 'openai')
    history = context.user_data.get('history', [SYSTEM_PROMPT])
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    history.append({"role": "user", "content": user_text})
    
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
    
    response = brain.generate_text(history, model=current_model)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –±–æ—Ç–∞
    history.append({"role": "assistant", "content": response})
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ (Rolling Window)
    # –û—Å—Ç–∞–≤–ª—è–µ–º System Prompt [0] –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 14 —Å–æ–æ–±—â–µ–Ω–∏–π
    if len(history) > 16:
        history = [history[0]] + history[-15:]
    
    context.user_data['history'] = history
    
    await update.message.reply_text(response)

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ Vision (GPT-4o)"""
    photo_file = await update.message.photo[-1].get_file()
    
    from io import BytesIO
    buffer = BytesIO()
    await photo_file.download_to_memory(buffer)
    img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
    
    user_caption = update.message.caption if update.message.caption else "–ß—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ?"
    
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
    
    # –î–ª—è Vision –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —á–∏—Å—Ç—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –¥–ª–∏–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏, 
    # –ª–∏–±–æ –¥–æ–±–∞–≤–ª—è—Ç—å –µ–≥–æ –≤ –∏—Å—Ç–æ—Ä–∏—é –∫–∞–∫ vision-–∫–æ–Ω—Ç–µ–Ω—Ç (—Å–ª–æ–∂–Ω–µ–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è).
    # –°–¥–µ–ª–∞–µ–º –æ–¥–Ω–æ—Ä–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏.
    payload_msg = [
        {"role": "user", "content": [
            {"type": "text", "text": user_caption},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"}}
        ]}
    ]
    
    response = brain.generate_text(payload_msg, model="gpt-4o") # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ gpt-4o –¥–ª—è –∑—Ä–µ–Ω–∏—è
    await update.message.reply_text(response)


# --- –ú–ï–ù–Æ –í–´–ë–û–†–ê –ú–û–î–ï–õ–ï–ô (–° –ü–ê–ì–ò–ù–ê–¶–ò–ï–ô) ---
async def show_models_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    brain.refresh_models()
    models = brain.text_models
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –º–æ–¥–µ–ª–µ–π (Telegram –Ω–µ –ø—É—Å—Ç–∏—Ç 100 –∫–Ω–æ–ø–æ–∫)
    keyboard = []
    for m in models[:10]:
        keyboard.append([InlineKeyboardButton(m, callback_data=f"setmod_{m}")])
    
    keyboard.append([InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫", callback_data="refresh_api")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    msg = f"üîç –ù–∞–π–¥–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –≤ API.\n–¢–µ–∫—É—â–∞—è: **{context.user_data.get('text_model')}**\n–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö:"
    await update.message.reply_text(msg, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)

async def callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    
    if data.startswith("setmod_"):
        new_model = data.replace("setmod_", "")
        context.user_data['text_model'] = new_model
        await query.edit_message_text(f"‚úÖ –£—Å–ø–µ—à–Ω–æ! –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ç–µ–ø–µ—Ä—å: **{new_model}**", parse_mode=ParseMode.MARKDOWN)
    
    elif data == "refresh_api":
        brain.text_models = [] # —Å–±—Ä–æ—Å –∫—ç—à–∞
        brain.refresh_models()
        await query.edit_message_text(f"–°–ø–∏—Å–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(brain.text_models)} –º–æ–¥–µ–ª–µ–π. –ù–∞–ø–∏—à–∏—Ç–µ /models —Å–Ω–æ–≤–∞.")

# --- –ó–ê–ü–£–°–ö ---
if __name__ == '__main__':
    app = ApplicationBuilder().token(TOKEN).build()
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("models", show_models_command))
    
    app.add_handler(CallbackQueryHandler(callback_handler))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    print("Bot is running with Context Management & Real API fetching...")
    app.run_polling()
