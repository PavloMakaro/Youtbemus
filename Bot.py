import logging
import requests
import time
import re
import json
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, InputMediaPhoto
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters, CallbackQueryHandler
from telegram.constants import ParseMode, ChatAction

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
TOKEN = "8377691734:AAGywySfCYU8lI9UWQUHW9CHdEKFXkl2fe8"

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –æ—à–∏–±–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏, –∞ –Ω–µ –≤ —á–∞—Ç–µ)
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

class PollinationsBrain:
    def __init__(self):
        self.text_url = "https://text.pollinations.ai/"
        self.image_base = "https://pollinations.ai/p/"
        
        # 1. –ñ–ï–°–¢–ö–ò–ô –°–ü–ò–°–û–ö –ë–ï–°–ü–õ–ê–¢–ù–´–• –ú–û–î–ï–õ–ï–ô (–°–∞–º—ã–µ –Ω–∞–¥–µ–∂–Ω—ã–µ)
        # 'openai' - —ç—Ç–æ –∞–≤—Ç–æ-—Ä–æ—É—Ç–µ—Ä –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—É—é —Å–µ–π—á–∞—Å –º–æ–¥–µ–ª—å (—á–∞—Å—Ç–æ gpt-4o-mini)
        self.safe_text_models = ["openai", "mistral", "mistral-large", "llama", "qwen", "searchgpt"]
        self.safe_image_models = ["flux", "flux-realism", "flux-anime", "flux-3d", "turbo"]
        
        self.current_text_model = "openai" # –°–∞–º–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    def generate_text_safe(self, messages, model_preference=None, seed=None):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç. 
        –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π 402/404, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ –∑–∞–ø–∞—Å–Ω—É—é.
        """
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, –±–µ—Ä–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é 'openai'
        model_to_use = model_preference if model_preference else "openai"
        
        payload = {
            "messages": messages,
            "model": model_to_use,
            "jsonMode": False
        }
        if seed: payload["seed"] = seed

        try:
            # –¢–∞–π–º–∞—É—Ç 60 —Å–µ–∫
            response = requests.post(self.text_url, json=payload, timeout=60)
            
            # –ï—Å–ª–∏ —É—Å–ø–µ—Ö
            if response.status_code == 200:
                return response.text
            
            # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ (402) –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (404) -> –ü–†–û–ë–£–ï–ú –ó–ê–ü–ê–°–ù–£–Æ
            if response.status_code in [402, 404]:
                logger.warning(f"Model {model_to_use} failed ({response.status_code}). Switching to backup.")
                # –§–æ–ª–±—ç–∫ –Ω–∞ 'openai' (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç)
                payload["model"] = "openai"
                fallback_resp = requests.post(self.text_url, json=payload, timeout=60)
                if fallback_resp.status_code == 200:
                    return f"{fallback_resp.text}\n\n_(–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ó–∞–ø—Ä–æ—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –æ—Ç–≤–µ—Ç –æ—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏)_"
                else:
                    return f"‚ö†Ô∏è –°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω (Error {fallback_resp.status_code}). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            
            return f"Error: {response.text}"

        except requests.exceptions.Timeout:
            return "‚ö†Ô∏è –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å."
        except Exception as e:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}"

    def generate_image_url(self, prompt, model="flux", seed=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É (–±–µ–∑ 404, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—Å—ã–ª–∫–∞)"""
        import urllib.parse
        # –û—á–∏—â–∞–µ–º –ø—Ä–æ–º–ø—Ç
        clean_prompt = re.sub(r'[^\w\s\-\.,]', '', prompt)[:300] # –£–±–∏—Ä–∞–µ–º –º—É—Å–æ—Ä, –æ–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω—É
        encoded = urllib.parse.quote(clean_prompt)
        
        # –°–ª—É—á–∞–π–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è seed, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ, —á—Ç–æ–±—ã –∫–∞—Ä—Ç–∏–Ω–∫–∏ –±—ã–ª–∏ —Ä–∞–∑–Ω—ã–º–∏
        if not seed:
            import random
            seed = random.randint(1, 999999)
            
        url = f"{self.image_base}{encoded}?width=1024&height=1024&model={model}&nologo=true&seed={seed}"
        return url, seed

brain = PollinationsBrain()

# --- –õ–û–ì–ò–ö–ê –ë–û–¢–ê ---

SYSTEM_PROMPT = {
    "role": "system", 
    "content": "You are a helpful AI assistant using Pollinations API. Be concise."
}

# --- –ü–†–û–í–ï–†–ö–ê –ò –°–ë–†–û–° –ö–û–ù–¢–ï–ö–°–¢–ê ---
async def check_context(context, chat_id):
    last_time = context.user_data.get('last_time', 0)
    if time.time() - last_time > 3600: # 1 —á–∞—Å
        context.user_data['history'] = [SYSTEM_PROMPT]
        context.user_data['last_time'] = time.time()
        return True
    context.user_data['last_time'] = time.time()
    return False

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data['history'] = [SYSTEM_PROMPT]
    context.user_data['txt_model'] = "openai"
    context.user_data['img_model'] = "flux"
    context.user_data['last_time'] = time.time()
    
    await update.message.reply_text(
        "üëã **–Ø –ø–æ—á–∏–Ω–∏–ª—Å—è!**\n\n"
        "–¢–µ–ø–µ—Ä—å —è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ö–æ–∂—É –ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏.\n"
        "–ü–∏—à–∏ —á—Ç–æ —É–≥–æ–¥–Ω–æ –∏–ª–∏ –ø—Ä–æ—Å–∏ *'–Ω–∞—Ä–∏—Å—É–π –∫–æ—Ç–∞'*.\n"
        "–ï—Å–ª–∏ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —è –∏—Å–ø–æ–ª—å–∑—É—é –∑–∞–ø–∞—Å–Ω—É—é.",
        parse_mode=ParseMode.MARKDOWN
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text
    chat_id = update.effective_chat.id

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ (—Å–±—Ä–æ—Å —á–µ—Ä–µ–∑ —á–∞—Å)
    if await check_context(context, chat_id):
        await update.message.reply_text("‚è≥ –ù–∞—á–∞–ª –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥ (–ø—Ä–æ—à–µ–ª —á–∞—Å).")

    # 2. –†—É—á–Ω–æ–π —Å–±—Ä–æ—Å
    if text.lower() in ['—Å–±—Ä–æ—Å', 'reset', '/reset']:
        context.user_data['history'] = [SYSTEM_PROMPT]
        await update.message.reply_text("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")
        return

    # 3. –°–º–µ–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ç–µ–∫—Å—Ç–æ–º ("–∏—Å–ø–æ–ª—å–∑—É–π –º–æ–¥–µ–ª—å mistral")
    lower_text = text.lower()
    if "–∏—Å–ø–æ–ª—å–∑—É–π" in lower_text or "use model" in lower_text:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        for m in brain.safe_text_models:
            if m in lower_text:
                context.user_data['txt_model'] = m
                await update.message.reply_text(f"‚úÖ –û–∫–µ–π, –ø—Ä–æ–±—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å: **{m}**", parse_mode=ParseMode.MARKDOWN)
                return
        for m in brain.safe_image_models:
            if m in lower_text:
                context.user_data['img_model'] = m
                await update.message.reply_text(f"üé® –î–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è —Ç–µ–ø–µ—Ä—å: **{m}**", parse_mode=ParseMode.MARKDOWN)
                return

    # 4. –†–∏—Å–æ–≤–∞–Ω–∏–µ
    draw_triggers = ["–Ω–∞—Ä–∏—Å—É–π", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π", "—Ñ–æ—Ç–æ", "draw", "image"]
    if any(text.lower().startswith(t) for t in draw_triggers):
        # –ß–∏—Å—Ç–∏–º –∑–∞–ø—Ä–æ—Å
        prompt = text
        for t in draw_triggers:
            prompt = re.sub(t, "", prompt, flags=re.IGNORECASE)
        
        model = context.user_data.get('img_model', 'flux')
        
        await context.bot.send_chat_action(chat_id, ChatAction.UPLOAD_PHOTO)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL
        img_url, seed = brain.generate_image_url(prompt, model=model)
        
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ (Telegram —Å–∞–º –∑–∞–≥—Ä—É–∑–∏—Ç –ø–æ —Å—Å—ã–ª–∫–µ)
            await update.message.reply_photo(img_url, caption=f"üñº **{model}** (Seed: {seed})", parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            # –ï—Å–ª–∏ Telegram –Ω–µ —Å–º–æ–≥ –∑–∞–≥—Ä—É–∑–∏—Ç—å (—Ç–∞–π–º–∞—É—Ç), –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–æ–π
            await update.message.reply_text(f"‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ —á–∞—Ç (—Å–µ—Ä–≤–µ—Ä –∑–∞–Ω—è—Ç), –Ω–æ –≤–æ—Ç —Å—Å—ã–ª–∫–∞:\n{img_url}")
        return

    # 5. –¢–µ–∫—Å—Ç
    current_model = context.user_data.get('txt_model', 'openai')
    history = context.user_data.get('history', [SYSTEM_PROMPT])
    history.append({"role": "user", "content": text})
    
    await context.bot.send_chat_action(chat_id, ChatAction.TYPING)
    
    # –í–ê–ñ–ù–û: –í—ã–∑–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    response_text = brain.generate_text_safe(history, model_preference=current_model)
    
    history.append({"role": "assistant", "content": response_text})
    if len(history) > 12: history = [history[0]] + history[-11:]
    context.user_data['history'] = history
    
    await update.message.reply_text(response_text)


# --- –ö–ù–û–ü–ö–ò (–¢–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ) ---
async def show_models(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = []
    # –¢–µ–∫—Å—Ç–æ–≤—ã–µ
    row = []
    for m in ["openai", "mistral", "searchgpt"]:
        row.append(InlineKeyboardButton(m, callback_data=f"set_{m}"))
    keyboard.append(row)
    
    # –ö–∞—Ä—Ç–∏–Ω–∫–∏
    row = []
    for m in ["flux", "flux-realism", "flux-anime"]:
        row.append(InlineKeyboardButton(m, callback_data=f"img_{m}"))
    keyboard.append(row)
    
    await update.message.reply_text("üõ† **–†–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏:**", reply_markup=InlineKeyboardMarkup(keyboard))

async def btn_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    
    if data.startswith("set_"):
        m = data.split("_")[1]
        context.user_data['txt_model'] = m
        await query.edit_message_text(f"–¢–µ–∫—Å—Ç: {m}")
    elif data.startswith("img_"):
        m = data.split("_")[1]
        context.user_data['img_model'] = m
        await query.edit_message_text(f"–ö–∞—Ä—Ç–∏–Ω–∫–∏: {m}")

if __name__ == '__main__':
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("models", show_models))
    app.add_handler(CallbackQueryHandler(btn_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    print("Bot fixed and running...")
    app.run_polling()
